#!/bin/bash -u
# Copyright 2015, 2016 Thomas Schatz, Xuan Nga Cao, Mathieu Bernard
#
# This file is part of abkhazia: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Abkhazia is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with abkahzia. If not, see <http://www.gnu.org/licenses/>.

# This is a simple kaldi recipe for use with the abkhazia library.
# Its main object is to compute a forced time-alignment from a trained
# acoustic model of a corpus. The language model is a n-gram, either
# at phone-level or word-level.

###### Parameters ######

# language model directory in the recipe
lang=@@@@

# feature parameters
use_pitch=@@@@

# speaker-independent triphone models parameters
num_states_si=@@@@
num_gauss_si=@@@@

# speaker-adaptive triphone models parameters
num_states_sa=@@@@
num_gauss_sa=@@@@


###### Recipe ######

[ -f cmd.sh ] && source ./cmd.sh \
  || echo "cmd.sh not found. Jobs may not execute properly."

. path.sh || { echo "Cannot source path.sh"; exit 1; }

# First finish preparing data
utils/utt2spk_to_spk2utt.pl data/main/utt2spk > data/main/spk2utt


# Features
mfccdir=mfcc
if [ "$use_pitch" = true ]
then
    make_feats="steps/make_mfcc_pitch.sh"
else
    make_feats="steps/make_mfcc.sh"
fi

echo "running $make_feats"
for x in main; do
(
    $make_feats \
        --nj 20 --cmd "$train_cmd" data/$x \
        exp/make_mfcc/$x $mfccdir;
    steps/compute_cmvn_stats.sh \
        data/$x exp/make_mfcc/$x $mfccdir;
) &
done
wait;


echo "training of the monophone model"
mkdir -p exp/mono;
steps/train_mono.sh \
    --nj 8 --cmd "$train_cmd" \
    data/main data/$lang exp/mono \
    > exp/mono/train.log

echo "training of the triphone model"

# first: forced alignment of train set with monophone model
mkdir -p exp/mono_ali
steps/align_si.sh \
    --nj 8 --cmd "$train_cmd" \
    data/main data/$lang exp/mono exp/mono_ali \
    > exp/mono_ali/align.log

# second: triphone model training
mkdir -p exp/tri1
steps/train_deltas.sh \
    --cmd "$train_cmd" \
    $num_states_si $num_gauss_si \
    data/main data/$lang exp/mono_ali exp/tri1 \
    > exp/tri1/train.log

echo "training the speaker adaptive triphone model"

# first: forced alignment with fmllr based on speaker independent
# triphone model
mkdir -p exp/tri1_ali_fmllr
steps/align_fmllr.sh \
    --nj 8 --cmd "$train_cmd" \
    data/main data/$lang exp/tri1 exp/tri1_ali_fmllr \
    > exp/tri1_ali_fmllr/align.log

# second: speaker adaptive training
mkdir -p exp/tri2a
steps/train_sat.sh \
    --cmd "$train_cmd" \
    $num_states_sa $num_gauss_sa \
    data/main data/$lang exp/tri1_ali_fmllr exp/tri2a \
    > exp/tri2a/train.log

# Final forced alignment
mkdir -p exp/tri2a_ali_fmllr
steps/align_fmllr.sh \
    --nj 1 --cmd "$train_cmd" \
    data/main data/$lang exp/tri2a exp/tri2a_ali_fmllr \
    >& exp/tri2a_ali_fmllr/align.log


##### Exporting results #####

echo "exporting results to export/forced_alignment.tra"
mkdir -p export
ali-to-phones \
    --write_lengths=true exp/tri2a/final.mdl \
    "ark,t:gunzip -c exp/tri2a_ali_fmllr/ali.1.gz|" \
    ark,t:export/forced_alignment.tra

# if we want to use the tri2a results directly without the final
# forced alignment (is there any difference between the two beyond one
# being done using only one job?)
# ali-to-phones \
#     --write_lengths=true exp/tri2a/final.mdl \
#     "ark,t:gunzip -c exp/tri2a/ali.*.gz|" \
#     ark,t:export/forced_alignment.tra
