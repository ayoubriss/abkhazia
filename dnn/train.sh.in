#!/bin/bash -u
# Copyright 2015, 2016 Thomas Schatz, Xuan-Nga Cao, Mathieu Bernard
#
# This file is part of abkhazia: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Abkhazia is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with abkahzia. If not, see <http://www.gnu.org/licenses/>.

# This is a kaldi recipe template for use with the abkhazia library.
# Its object is to:
#
# - prepare the data from an abkhazia/kaldi corpus
# - compute MFCC features
# - train a GMM-HMM model with triphone word-position-dependent states
#   and speaker adaptation

###### Parameters ######

# data directory in the recipe, specified by the --name option of
# the command 'abkhazia train'
name=@@@@

# do all computation or focus on main ones
optional_silence=@@@@

# feature parameters
use_pitch=@@@@

# speaker-independent triphone models parameters
num_states_si=@@@@
num_gauss_si=@@@@

# speaker-adaptive triphone models parameters
num_states_sa=@@@@
num_gauss_sa=@@@@


###### Recipe ######
nj=3

[ -f cmd.sh ] && source ./cmd.sh \
        || echo "cmd.sh not found. Jobs may not execute properly."

. path.sh || { echo "Cannot source path.sh"; exit 1; }


# Finish preparing data

utils/utt2spk_to_spk2utt.pl data/$name/utt2spk > data/$name/spk2utt || exit 1

if [ "$optional_silence" = true ] ; then
    sil_prob=0.5
else
    sil_prob=0.0
fi

echo "running utils/prepare_lang.sh"
utils/prepare_lang.sh \
    --position-dependent-phones true \
    --sil_prob $sil_prob \
    data/local/dict "<unk>" data/local/lang_tmp data/lang \
    >& data/prepare_lang.log || exit 1


# Features

mfccdir=mfcc
if [ "$use_pitch" = true ]
then
    make_feats="steps/make_mfcc_pitch.sh"
else
    make_feats="steps/make_mfcc.sh"
fi

echo "running $make_feats"
for x in $name
do
    (
        $make_feats \
            --nj "$nj" --cmd "$train_cmd" data/$x \
            exp/make_mfcc/$x $mfccdir;
        steps/compute_cmvn_stats.sh \
            data/$x exp/make_mfcc/$x $mfccdir;
    ) &
done
wait;


# Monophone model training

echo -n "training the monophone model..."
mkdir -p exp/mono;
steps/train_mono.sh \
    --nj "$nj" --cmd "$train_cmd" \
    data/$name data/lang exp/mono \
    > exp/mono/train.log || exit 1
echo " done"


# Triphone model training

echo -n "force-aligning corpus with the monophone model..."
mkdir -p exp/mono_ali
steps/align_si.sh \
    --nj "$nj" --cmd "$train_cmd" \
    data/$name data/lang exp/mono exp/mono_ali \
    > exp/mono_ali/align.log || exit 1
echo " done"

echo -n "training speaker-independant triphone model..."
mkdir -p exp/tri1
steps/train_deltas.sh \
    --cmd "$train_cmd" \
    $num_states_si $num_gauss_si \
    data/$name data/lang exp/mono_ali exp/tri1 \
    > exp/tri1/train.log || exit 1
echo "  done"


# Speaker adaptive triphone model training

echo -n "forced-aligning corpus with the speaker-independent triphone model..."
mkdir -p exp/tri1_ali_fmllr
steps/align_fmllr.sh \
    --nj "$nj" --cmd "$train_cmd" \
    data/$name data/lang exp/tri1 exp/tri1_ali_fmllr \
    > exp/tri1_ali_fmllr/align.log || exit 1
echo " done"

echo -n "training speaker-adaptive triphone model..."
mkdir -p exp/tri2a
steps/train_sat.sh \
    --cmd "$train_cmd" \
    $num_states_sa $num_gauss_sa \
    data/$name data/lang exp/tri1_ali_fmllr exp/tri2a \
    > exp/tri2a/train.log || exit 1
echo " done"

# Deep neural network training

echo -n "forced-aligning corpus with the speaker-adaptive triphone model..."
mkdir -p exp/tri2a_ali
steps/align_fmllr.sh \
    --nj "$nj" --cmd "$train_cmd" \
    data/$name data/lang exp/tri2a exp/tri2a_ali \
    > exp/tri2a_ali/align.log || exit 1
echo " done"

echo -n "training neural network..."
mkdir -p exp/dnn
steps/nnet2/train_pnorm_fast.sh \
    --stage -10 \
    --samples-per-iter 400000 \
    --minibatch-size 256 \
    --num-jobs-nnet 2 \
    --initial-learning-rate 0.01 --final-learning-rate 0.001 \
    --num-hidden-layers 4 \
    --pnorm-input-dim 2000 --pnorm-output-dim 400 \
    --cmd "$train_cmd" \
    data/train data/lang exp/tri2a_ali exp/dnn \
    > exp/dnn/train.log || exit 1
    # --parallel-opts --num-threads "$nj" \
echo " done"
